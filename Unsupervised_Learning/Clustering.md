# **Clustering Algorithm**
μ μ‚¬μ„±μ΄ λ†’μ€ λ°μ΄ν„°λ“¤μ„ λ™μΌν• κ·Έλ£ΉμΌλ΅ λ¶„λ¥ν•κ³  μ„λ΅ λ‹¤λ¥Έ κµ°μ§‘λ“¤μ΄ μƒμ΄μ„±μ„ κ°€μ§€λ„λ΅ κ·Έλ£Ήν™”ν•λ” μ•κ³ λ¦¬μ¦ </br>
μΆ‹μ€ κµ°μ§‘μΌμλ΅ λ­‰μ³μμΌλ©°, λ‹¤λ¥Έ κµ°μ§‘κ³Ό λ–¨μ–΄μ Έμλ‹¤(μ°¨μ› μ¶•μ†λ΅ ν™•μΈ κ°€λ¥)</br></br>

**λ€ν‘μ μΈ μΆ…λ¥λ“¤**</br>
K-Means, Mean shift, Gaussian Mixture Model, DBSCAN </br>
fit()μΌλ΅ κµ°μ§‘ν™” ν›„, fit_predict()λ΅ label λ°ν™

## **Test_Data for Clustering**
Clustering Algorithm μ„±λ¥ ν‰κ°€λ¥Ό μ„ν• ν…μ¤νΈ λ°μ΄ν„° μƒμ„± λ°©λ²• - sklearn.datasets / makeblobs() </br></br>

**νλ¦¬λ―Έν„°** : n_samples = μƒμ„±ν•  μ΄ λ°μ΄ν„°μ κ°μ </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
n_features = λ°μ΄ν„° featureμ κ°μ (μ‹κ°ν™”κ°€ λ©μ μΌ μ‹ 2λ΅ μ„¤μ •ν•΄ 2μ°¨μ› ν‰λ©΄ ν‘ν„)</br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
centers = κµ°μ§‘μ κ°μ / ndarrayλ΅ μ¤‘μ‹¬μ μ μΆν‘ (=targetμ κ°μ)</br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cluster_std = μƒμ„±λ  κµ°μ§‘ λ‚΄ λ°μ΄ν„°μ ν‘μ¤€νΈμ°¨ </br></br>

makeblobs()λ¥Ό ν†µν•΄ λ°ν™ λ feature dataλ¥Ό ν‰κ°€ν•  λ¨λΈμ— ν•™μµμ‹μΌ ν…μ¤νΈ targetκ³Ό λΉ„κµ

## **μ„±λ¥ ν‰κ°€**
**μ‹¤λ£¨μ—£ λ¶„μ„** : κ° κµ°μ§‘κ°„μ κ±°λ¦¬κ°€ μ–Όλ§λ‚ ν¨μ¨μ μΌλ΅ λ¶„λ¦¬λΌ μλ”μ§€λ¥Ό λ‚νƒ€λ‚Έλ‹¤ -> s(i) = ( b(i) - a(i) ) / max( a(i), b(i) )</br>
\# ai = iλ²μ§Έ λ°μ΄ν„°μ— λ€ν•΄ μμ‹ μ΄ μ†ν•΄μλ” κµ°μ§‘μ—μ„ λ‹¤λ¥Έ λ°μ΄ν„° ν¬μΈν„°λ“¤μ κ±°λ¦¬ ν‰κ· </br>
&nbsp;&nbsp;
bi = iλ²μ§Έ λ°μ΄ν„°μ— λ€ν•΄ κ°€μ¥ κ°€κΉμ΄ κµ°μ§‘ λ‚΄μ— λ‹¤λ¥Έ λ°μ΄ν„° ν¬μΈν„°λ“¤μ κ±°λ¦¬ ν‰κ·  </br>
&nbsp;&nbsp;
a(i)λ” μ‘μ„μλ΅, b(i)λ” ν΄μλ΅ μΆ‹μ€ μ§€ν‘ </br>
&nbsp;&nbsp;
κ³„μλ” -1\~1μ λ²”μ„λ¥Ό κ°€μ§€λ©°, 1λ΅ κ°€κΉμ›μ§μλ΅ μ΄μƒμ μΈ μ§€ν‘λ©°, 0μ— κ°€κΉμΈμλ΅ λ‹¤λ¥Έ κµ°μ§‘κ³Ό κ°€κΉλ‹¤λ” μλ―Έ </br>
&nbsp;&nbsp;
'-'κ°’μ€ μ•„μ λ‹¤λ¥Έ κµ°μ§‘ λ°μ΄ν„° ν¬μΈν„°κ°€ ν• λ‹Ή λμμ„ μλ―Έ (κµ°μ§‘ν™”μ— λ¬Έμ κ°€ μμ) </br></br>
κ°λ³„ λ°μ΄ν„°κ°€ κ°€μ§€λ” κµ°μ§‘ν™”μ μ§€ν‘μΈ μ‹¤λ£¨μ—£ κ³„μ(silhouette coefficient)λ¥Ό κΈ°λ°μΌλ΅ ν•λ‹¤ </br>
μ΄λ” ν•΄λ‹Ή λ°μ΄ν„°κ°€ κ°™μ€ κµ°μ§‘ λ‚΄μ λ°μ΄ν„°μ™€ μ–Όλ§λ‚ κ°€κΉκ² κµ°μ§‘ν™” λμ–΄μκ³ , λ‹¤λ¥Έ κµ°μ§‘ λ°μ΄ν„°μ™€λ” μ–Όλ§λ‚ λ©€λ¦¬ λ¶„λ¦¬λμ–΄ μλ”μ§€λ¥Ό λ‚νƒ€λ‚΄λ” μ§€ν‘ </br></br>

silhouette_samples(X, labels, metric = 'euclidean', **kwds) : μ‹¤λ£¨μ—£ κ³„μλ¥Ό κ³„μ‚°ν•΄ λ°ν™ </br>
silhouette_score(X, labels, metric = 'euclidean', sample_size = None **kwds) : μ „μ²΄ λ°μ΄ν„°μ μ‹¤λ£¨μ—£ κ³„μλ¥Ό ν‰κ· ν•΄ λ°ν™ </br></br>
**μ „μ²΄ μ‹¤λ£¨μ—£ κ³„μ ν‰κ· κ³Ό λ”λ¶μ–΄ κ°λ³„ κµ°μ§‘μ ν‰κ· κ°’μ νΈμ°¨κ°€ μ‘μ•„μ•Όμ§€ μΆ‹μ€ μ„±λ¥μ κµ°μ§‘μ΄λ‹¤ -> κ°λ³„ κµ°μ§‘μ κ³„μμ™€ ν‰κ· μ΄ μ μ‚¬** </br></br>
λ¨λΈμ—μ„μ n_clustersμ κ°’, μ¦‰ κµ°μ§‘μ κ°μμ— λ”°λΌ μ‹¤λ£¨μ—£ κ³„μκ°€ λ‹¬λΌμ§</br>
κ°μκ°€ μ‘μΌλ©΄ λ λ„λ¬΄ μΌλ°ν™”κ°€ μΌμ–΄λ‚λ―€λ΅, κµ°μ§‘ν™” λ λ²¨μ— λ”°λ¥Έ μ‹κ°ν™”λ¥Ό ν†µν•΄ κ°κ° κµ°μ§‘μ κ³„μμ™€ μ „μ²΄ ν‰κ· μ„ λΉ„κµν•λ©° μΆ‹μ€ μ„±λ¥μ„ λ‚νƒ€λ‚΄λ” λ¨μ–‘μ κµ°μ§‘μ κ°μλ¥Ό μ°Ύλ” μµμ ν™” κ³Όμ •μ΄ ν•„μ”

## **K-Means**
κµ°μ§‘μ Centroidλ¥Ό μ„¤μ •ν•΄ κµ°μ§‘ν™”ν•λ” κΈ°λ²• - sklearn.cluster / KMeans()</br></br>
**μμ„** </br>
step1. nκ°μ κµ°μ§‘ μ¤‘μ‹¬μ (centroid) μ„¤μ • </br>
step2. κ° λ°μ΄ν„°λ“¤μ€ κ±°λ¦¬λ¥Ό κ³„μ‚°ν•΄ κ°€μ¥ κ°€κΉμ΄ μ¤‘μ‹¬μ  μ„ νƒ </br>
step3. μ¤‘μ‹¬μ μ€ λ³ΈμΈμ—κ² ν• λ‹Ή λ, λ°μ΄ν„°λ“¤μ ν‰κ·  μ¤‘μ‹¬(κ±°λ¦¬)μΌλ΅ μ΄λ™ </br>
step4. κ°κ°μ μ¤‘μ‹¬μ μ— ν• λ‹Ή λ λ°μ΄ν„°μ μΆ…λ¥κ°€ λ³€κ²½λμ§€ μ•μ„ λ• κΉμ§€, 1\~3 λ°λ³µ </br> </br>
μ¥μ  : μΌλ°μ μ΄λ©° κ°€μ¥ λ§μ΄ ν™μ© + μ‰½κ³  κ°„κ²° + λ€μ©λ‰ λ°μ΄ν„° ν™μ© κ°€λ¥ </br>
λ‹¨μ  : κ±°λ¦¬ κΈ°λ°μΌλ΅ μ†μ„± μκ°€ λ§μΌλ©΄ μ„±λ¥ ν•λ½(PCAν™μ© ν•„μ”ν•  μ μμ) + λ°λ³µ νμ λ§μ„ μ‹ μ†λ„ μ €ν• + μ΄μƒμΉ λ°μ΄ν„°μ— μ·¨μ•½ </br></br>

**νλΌλ―Έν„°** : n_clusters = μ¤‘μ‹¬μ μ κ°―μ </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
init = μ΄κΈ° μ¤‘μ‹¬μ  μΆν‘ μ„¤μ • λ°©μ‹ (μΌλ°μ μΌλ΅  'k-means++' μ„¤μ •) </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
max_iter = μµλ€ λ°λ³µ νμ </br></br>
**μ†μ„±** : labels_ = κ° λ°μ΄ν„°κ°€ μ†ν• κµ°μ§‘ μ¤‘μ‹¬μ μ„ λ‚νƒ€λ‚Έ λ μ΄λΈ” λ°ν™</br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
cluster_centers_ = κ° κµ°μ§‘ μ¤‘μ‹¬μ  μΆν‘ -> μ‹κ°ν™” μ΄μ© κ°€λ¥</br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
\#shapeλ” (κµ°μ§‘ κ°μ, feature κ°μ)λ¥Ό λ‚νƒ€λƒ„ </br></br>

μ μμ‚¬ν•­ :  fit()λ§ ν•΄λ„ κµ°μ§‘ ν• λ‹Ήλλ©°, fit_predict(feature)μ€ labels_λ¥Ό 2d ndarrayλ΅ / fit_transformμ€ λ°μ΄ν„°λ³„λ΅ κ°κ°μ μ¤‘μ‹¬μ κ³Όμ κ±°λ¦¬λ¥Ό 2d ndarrayλ΅ λ°ν™

## **Mean Shift**
KDE(Kernel Density Estimation)λ¥Ό μ΄μ©ν•μ—¬ λ°μ΄ν„° ν¬μΈν„°λ“¤μ΄ λ°μ΄ν„° λ¶„ν¬κ°€ λ†’μ€ κ³³μΌλ΅ μ΄λ™ν•λ©° κµ°μ§‘ν™” μν–‰ - sklearn.cluster / MeanShift()</br>
λ³„λ„μ κµ°μ§‘ κ°μλ¥Ό μ§€μ •ν•μ§€ μ•μΌλ©° Bandwidthμ— κΈ°λ°ν•μ—¬ μλ™μΌλ΅ κ°μλ¥Ό μ •ν•¨ </br>
λΉ„λ¨μμ  μ¶”μ • : λ°μ΄ν„°κ°€ νΉμ • λ¶„ν¬λ¥Ό λ”°λ¥΄μ§€ μ•λ”λ‹¤λ” κ°€μ • ν•μ—μ„ λ°€λ„ μ¶”μ • - κ΄€μΈ΅λ λ°μ΄ν„° λ§μΌλ΅ λ°€λ„ μ°ΎκΈ° </br></br>
**μμ„**</br>
step1. κ°λ³„ λ°μ΄ν„°μ νΉμ • λ°κ²½ λ‚΄μ— μ£Όλ³€ λ°μ΄ν„°λ¥Ό ν¬ν•¨ν• λ°μ΄ν„° λ¶„ν¬λ„ κ³„μ‚°  </br>
\# λ°μ΄ν„° κ°κ°μ— μ»¤λ„ ν•¨μλ¥Ό μ μ©ν• κ°’μ„ λ¨λ‘ λ”ν• ν›„ λ°μ΄ν„° κ±΄μλ΅ λ‚λ” = ν™•λ¥  λ°€λ„ ν•¨μ PDF</br>
(μ‰½κ² μƒκ°ν•λ©΄ κ°κ° λ°μ΄ν„°λ“¤μ λ°€λ„ν•¨μλ“¤μ„ λ”ν•΄ μ „μ²΄ μλ΅ λ‚λ„μ–΄ ν•λ‚μ μ—°μ†μ μΈ μ „μ²΄ λ°€λ„λ¥Ό λ‚νƒ€λƒ„)</br>
step2. μ¤‘μ‹¬μ μ„ λ°μ΄ν„° λ¶„ν¬λ„κ°€ κ°€μ¥ λ†’μ€ κ³³μΌλ΅ μ΄λ™ </br>
step3. μ¤‘μ‹¬μ μ„ λ”°λΌ ν•΄λ‹Ή λ°μ΄ν„°λ“¤ μ£Όλ³€ λ°μ΄ν„°μ™€μ κ±°λ¦¬κ°’μ„ kernel ν•¨μκ°’μΌλ΅ μ…λ ¥ν• λ’¤, λ°ν™ κ°’μ„ ν„μ¬ μ„μΉμ—μ„ μ—…λ°μ΄νΈν•λ©° μ΄λ™ </br>
step4. λ°μ΄ν„°μ μ›€μ§μ„μ΄ μ—†μ„ λ•κΉμ§€ 1\~3 λ°λ³µν•μ—¬ μµμΆ… κµ°μ§‘ μ¤‘μ‹¬μ  μ°ΎκΈ° </br></br>

**KDE** = (1 / n*h) * Ξ£( K (X - Xi) / h ) >> K : μ»¤λ„ ν•¨μ, h = bandwidth (ν‘μ¤€νΈμ°¨μ™€ λ™μΌ) </br>
**kernel function** : Gaussian Distribution(λ€ν‘μ ), Uniform Distribution</br>
K - Gaussian Distribution = ( 1 / (2πΏΟƒ^2)^(1/2) ) * e^(- ( x - ΞΌ)^2 / 2Οƒ^2) ) = General Normal ~ N(ΞΌ, Οƒ^2)</br>
h - μ‘μ€ hκ°’μ€ μΆκ³  spikeν• KDEλ΅ λ³€λ™μ„±μ΄ ν° PDFλ¥Ό μ¶”μ • (overfitting μ„ν—μ„±) / ν° hκ°’μ€ κ³Όλ„ν•κ² smoothingλ KDEλ΅ λ‹¨μν™”λ PDFλ¥Ό μ¶”μ • (undefitting μ„ν—μ„±) -> bandwidthκ°€ μ‘μ„μλ΅ λ§μ€ μ¤‘μ‹¬μ  μƒμ„± </br> 
**μµμ μ h** = (4Οƒ^5 / 3n)^(1/5) β‰ 1.06Οƒn^(-1/5) - estimate_bandwidth(data, quantile = samplingμ‹ ν•„ν„°λ§ λΉ„μ¨) ν•¨μλ΅ κ³„μ‚° λ° λ°ν™ </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
λ°μ΄ν„°κ°€ ν΄μλ΅ quantileμ„ ν‚¤μ› μν–‰ μ‹κ°„μ„ μ¤„μ—¬μ¤„ ν•„μ” μ΅΄μ¬</br>
**KDE μ‹κ°ν™”** : seabornμ—μ„μ displot()μ΄ KDE λ°©μ‹μΌλ΅ PDFλ¥Ό λ‚νƒ€λƒ„ - sns.distplot(data)</br>
νλΌλ―Έν„° - rug = λ°€μ§‘λ„ ν‘μ‹ True/False, hist = νμ¤ν† κ·Έλ¨ True/False, kde = KDEν•¨μ True/False, . . . </br>
νΉμ€ sns.kdeplot(data)μΌλ΅ kde ν•¨μλ§ μμ„Έν νμ•… κ°€λ¥ - νλ¦¬λ―Έν„° : bw = bandwidth μμΉ</br></br>

**νλΌλ―Έν„°** : bandwidth = bandwidthκ°’μ΄λ©° MeanShift κµ°μ§‘ν™”μ μ„±λ¥μ„ κ²°μ •ν•λ” κ°€μ¥ μ¤‘μ”ν• μ”μ†</br></br>
bandwidthμ— λ„λ¬΄ λ―Όκ°ν• μ΄μκ°€ μ΅΄μ¬ -> λ°μ΄ν„° λ§μ΄λ‹λ³΄λ‹¨ μμƒ μ²λ¦¬μ— μ£Όλ΅ μ‚¬μ©

## **GMM(Gaussian Mixture Model)**
K-meansλ” κ±°λ¦¬κΈ°λ° μ•κ³ λ¦¬μ¦ μ΄κΈ°μ— μ¤‘μ‹¬μ μ„ κΈ°λ°μΌλ΅ λΉ„μ·ν• κ±°λ¦¬μ μΌλ΅ νΌμ Έμλ” λ°μ΄ν„°μ—λ” ν¨μ¨μ μ΄μ§€λ§, κµ°μ§‘λ“¤μ΄ μΌμ§μ„  μƒμ΄ λ†“μ—¬ μλ‹¤λ“ μ§€, κ²Ήμ³μλ‹¤λ“ μ§€ λ“±μ— λ€ν• λ°μ΄ν„° λ¶„ν¬μ—λ” μ–΄λ ¤μ›€μ΄ μ΅΄μ¬ν•λ‹¤</br>
μ΄λ¥Ό ν•΄κ²°ν•κΈ° μ„ν• κµ°μ§‘λ“¤μ λ°μ΄ν„°λ“¤μ΄ μ—¬λ¬ κ°€μ°μ‹μ• λ¶„ν¬(Gaussian Distribution)λ¥Ό κ°€μ§€λ” λ¨λΈλ΅ κ°€μ •ν•λ” κΈ°λ²• - sklearn.mixture / GaussianMixture()</br>
λ¨μμ  μ¶”μ • : λ°μ΄ν„°κ°€ νΉμ • λ°μ΄ν„° λ¶„ν¬λ¥Ό λ”°λ¥Έλ‹¤λ” κ°€μ •ν•μ— λ°μ΄ν„° λ¶„ν¬λ¥Ό μ°Ύλ” λ°©λ²•</br>
->κ°λ³„ μ •κ· λ¶„ν¬λ“¤μ ν‰κ· κ³Ό λ¶„μ‚°, λ°μ΄ν„°κ°€ νΉμ • μ •κ· λ¶„ν¬μ— ν•΄λ‹Ήλ  ν™•λ¥  μ¶”μ • ν•„μ”</br></br>
μ›λ³Έ λ°μ΄ν„° κ³΅μ„ μ΄ μ—¬λ¬ μ •κ·λ¶„ν¬λ΅ μ΄λ£¨μ–΄μ Έμλ‹¤κ³  κ°€μ •ν•κ³  λ°μ΄ν„°κ°€ μ–΄λ μ •κ·λ¶„ν¬μ— ν•΄λ‹Ήν•λ” μ§€ μ°Ύλ” κ²ƒ</br></br>

**μμ„** </br>
step1. Expectation : κ°λ³„ λ°μ΄ν„°λ“¤ κ°κ°μ— λ€ν•΄ μ •κ· λ¶„ν¬μ— μ†μ†λ  ν™•λ¥ μ„ κµ¬ν•κ³  κ°€μ¥ λ†’μ€ ν™•λ¥ μ„ κ°€μ§„ μ •κ· λ¶„ν¬μ— μ†μ† </br>
\# λ‹¨, μµμ΄ μ‹μ—λ” μ›λ³Έ κ³΅μ„ μΌλ΅λ¶€ν„° λ¶„ν¬λ¥Ό λ‚λ„μ§€ μ•μ€ μƒν™©μ΄λ―€λ΅, μ„μλ΅ νΉμ • μ •κ· λ¶„ν¬λ΅ μ†μ† </br>
step2. Maximization : μ†μ†λ ν›„, Expectationμ—μ„ κµ¬ν• μ •κ· λ¶„ν¬λ“¤μ ν‰κ· κ³Ό λ¶„μ‚°μ„ κµ¬ν•κ³  μ΄λ¥Ό κΈ°λ°μΌλ΅ λ‹¤μ‹ λ°μ΄ν„°κ°€ λ°κ²¬λ  κ°€λ¥λ„λ¥Ό μµλ€ν™”(Maximum likelihood) ν•  μ μλ„λ΅ ν‰κ· κ³Ό λ¶„μ‚°(λ¨μ)λ¥Ό κµ¬ν•¨ </br>
step3. κ°λ³„ μ •κ·λ¶„ν¬λ“¤μ ν‰κ· κ³Ό λ¶„μ‚°μ΄ λ³€κ²½λμ§€ μ•κ³ , λ°μ΄ν„°λ“¤μ μ†μ†μ΄ λ³€κ²½λμ§€ μ•μ„ λ•κΉμ§€ 1\~2(EM) λ°λ³µ</br>
(λ°μ΄ν„°λ“¤μ„ λ¨Όμ € ν• λ‹Ήν•κ³  κ³„μ‚°ν•΄ λ³€κ²½ν•κ³  λ‹¤μ‹ ν• λ‹Ήν•κ³  λ°λ³µν•λ‹¤λ” μ μ—μ„ K-Meansμ™€ μ μ‚¬) </br></br>

**νλΌλ―Έν„°** : n_components = Mixture Modelμ κ°μλ΅ κµ°μ§‘ν™”μ κ°μλ¥Ό μλ―Έ</br>
predict()μΌλ΅λ„ label λ°ν™ κ°€λ¥

## **DBSCAN(Density Based Spatial Clustering of Applications with Noise)**
νΉμ • κ³µκ°„ λ‚΄μ— λ°μ΄ν„° λ°€λ„ μ°¨μ΄λ¥Ό κΈ°λ°μΌλ΅ ν•λ” μ•κ³ λ¦¬μ¦ - sklearn.cluster / DBSCAN()</br>
κ·Όμ² λ°μ΄ν„°λ“¤μ΄ μ μ • λ°€λ„κ°€ μ μ§€λλ‹¤λ©΄, κ³„μ† κµ°μ§‘μ„ μ΄μ–΄λ‚κ° </br>
-> λ³µμ΅ν• κΈ°ν•ν•μ  λ¶„ν¬λ„λ¥Ό κ°€μ§„ λ°μ΄ν„° μ„ΈνΈμ—μ„λ„ κµ°μ§‘ν™”λ¥Ό μ μν–‰ / λ°μ΄ν„° λ°€λ„ μ°¨μ΄λ¥Ό κ°μ§€ν•μ—¬ μλ™μΌλ΅ κµ°μ§‘ μƒμ„± </br></br>
λ‹¨μ  : λ°μ΄ν„° λ°€λ„κ°€ μμ£Ό λ³€ν•κ±°λ‚, λ¨λ“  λ°μ΄ν„°μ λ°€λ„κ°€ ν¬κ² λ³€ν•μ§€ μ•μΌλ©΄ μ„±λ¥ ν•λ½ + feature κ°μκ°€ λ§μΌλ©΄ μ„±λ¥ ν•λ½ </br>
\# λ°€λ„κ°€ μ΄μ–΄μ§€μ§€ μ•μΌλ©΄ noiseλ΅ μ²λ¦¬ν•κΈ° λ•λ¬Έ </br></br>

**κµ¬μ„± μ”μ†** : epsilon = κ°λ³„ λ°μ΄ν„°λ¥Ό μ¤‘μ‹¬μΌλ΅ μ…μ‹¤λ΅  λ°κ²½μ„ κ°€μ§€λ” μ›ν•μ μμ—­ </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
min points = κ°λ³„ λ°μ΄ν„°μ μ…μ‹¤λ΅  μ£Όλ³€ μμ—­μ— ν¬ν•¨λλ” μµμ† νƒ€ λ°μ΄ν„°μ κ°μ ( = κµ°μ§‘μ„ μ„ν• μ μ • λ°€λ„ )</br></br>
**ν¬μΈνΈ μΆ…λ¥** : ν•µμ‹¬ ν¬μΈνΈ(Core Point) = epsilon λ‚΄μ— min points μ΄μƒμ λ°μ΄ν„°λ¥Ό κ°€μ§€κ³  μλ” ν¬μΈνΈ </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
μ΄μ›ƒ ν¬μΈνΈ(Neighbor Point) = epsilon λ‚΄ μ„μΉν• λ‹¤λ¥Έ ν¬μΈνΈ </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
κ²½κ³„ ν¬μΈνΈ(Border Point) = epsilon λ‚΄ min pointsλ³΄λ‹¤ μ μ€ λ°μ΄ν„°λ¥Ό κ°€μ΅μ§€λ§, ν•µμ‹¬ ν¬μΈνΈλ¥Ό μ΄μ›ƒ ν¬μΈνΈλ΅ κ°€μ§„ ν¬μΈνΈ </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
μ΅μ ν¬μΈνΈ(Noise Point) = epsilon λ‚΄ min pointsλ³΄λ‹¤ μ‘μ€ λ°μ΄ν„°λ¥Ό κ°€μ§€λ©°, ν•µμ‹¬ ν¬μΈνΈλ„ μ΄μ›ƒ ν¬μΈνΈλ΅ κ°€μ§€μ§€ μ•μ€ ν¬μΈνΈ </br></br>

**μμ„** </br>
step1. eplisonκ³Ό min pointsλ¥Ό κΈ°λ°μΌλ΅ Core Pointλ¥Ό ν•λ‚ μ„ νƒ </br>
step2. μ΄ν›„ λ°κ²½ λ‚΄ Core Point ν•λ‚λ¥Ό λ” μ„ νƒ </br>
step3. Core Pointλ“¤μ„ μ—°κ²°ν• ν›„ μ΄λ™ν•μ€μ„ λ• κ·Έλ ¤μ§€λ” μμ—­ λ‚΄ ν¬μΈνΈλ“¤μ€ λ¨λ‘ κ°™μ€ κµ°μ§‘μΌλ΅ νμ•… </br>
step4. μ΄ν›„ μƒλ΅μ΄ Core Pointλ¥Ό κΈ°μ¤€μΌλ΅ 2\~3 λ°λ³µν•λ©° λ°κ²½ λ‚΄ Core Pointκ°€ μ—†μ„ λ•κΉμ§€ μμ—­μ„ ν™•μ¥ </br></br>

**νλΌλ―Έν„°** : eps = epsilon / min_samples = min points + 1 (μμ‹  λ°μ΄ν„°λ„ ν¬ν•¨) / metric = 'euclidean' - κ±°λ¦¬ μΈ΅μ • λ°©μ‹ </br></br>
Noise Pointλ” labelμ„ -1λ΅ λ°ν™